# -*- coding: utf-8 -*-
"""Milestone 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ONTISdu3IeVj_91XieLvvxP0-nhCFnca
"""

import os
os.makedirs("data/processed", exist_ok=True)
print("Folder created at:", os.path.abspath("data/processed"))

"""
cleaning_pipeline.py
--------------------------
Simple, reliable preprocessing pipeline for Predictive Transaction Intelligence (BFSI).
This version handles:
 - Missing values
 - Duplicate removal
 - Column normalization
 - Feature engineering
 - One-hot encoding (for categorical columns)

"""

import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder

# 1️) Load Raw Data

RAW_PATH = "/content/fraud_detection_dataset_LLM (2).csv"
OUTPUT_PATH = "data/processed/transactions_clean.csv"

print(" Loading dataset...")
df = pd.read_csv(RAW_PATH)
print(f" Loaded {len(df)} records and {df.shape[1]} columns")


# 2️) Handle Missing Values

print("\n Handling missing values...")
if 'kyc_verified' in df.columns:
    df['kyc_verified'] = df['kyc_verified'].fillna("No")

if 'transaction_amount' in df.columns:
    df.dropna(subset=["transaction_amount"], inplace=True)

# 3️) Remove Duplicates

print("\n Removing duplicates...")
df.drop_duplicates(subset=["transaction_id"], inplace=True)


# 4️) Standardize and Clean Columns

print("\n Standardizing columns...")
if 'timestamp' in df.columns:
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

if 'channel' in df.columns:
    df['channel'] = df['channel'].astype(str).str.title().str.strip()

if 'kyc_verified' in df.columns:
    df['kyc_verified'] = df['kyc_verified'].astype(str).str.title().str.strip()

if 'transaction_amount' in df.columns:
    df['transaction_amount'] = df['transaction_amount'].astype(float)


id_cols = df[['transaction_id', 'customer_id']] if 'transaction_id' in df.columns and 'customer_id' in df.columns else None

# 5) Feature Engineering

print("\n Creating new features...")
if 'timestamp' in df.columns:
    df['hour'] = df['timestamp'].dt.hour
    df['weekday'] = df['timestamp'].dt.weekday
    df['month'] = df['timestamp'].dt.month

if 'transaction_amount' in df.columns:
    df['is_high_value'] = (df['transaction_amount'] > 50000).astype(int)
    df['transaction_amount_log'] = np.log1p(df['transaction_amount'])

# 6) Encode Categorical Columns

print("\n Encoding categorical columns...")
categorical_cols = [col for col in ['channel', 'kyc_verified'] if col in df.columns]

if categorical_cols:
    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    encoded_array = encoder.fit_transform(df[categorical_cols])
    encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))
    df = pd.concat([df.reset_index(drop=True), encoded_df], axis=1)
    df.drop(columns=categorical_cols, inplace=True)
    print(f" Encoded columns added: {list(encoded_df.columns)}")
else:
    print(" No categorical columns found for encoding.")

# 7) Save Cleaned Data

print("\nSaving cleaned dataset...")
os.makedirs("data/processed", exist_ok=True)



df.to_csv(OUTPUT_PATH, index=False)
print(f" Data preprocessing complete — {len(df)} rows saved.")
print(f" Cleaned file saved to: {os.path.abspath(OUTPUT_PATH)}")

